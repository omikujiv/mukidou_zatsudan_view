# 使用方法

test_word2Vec.ipynb以外に必要なファイル
* Word2Vecのモデル

* 話題データ.csv

モデルファイルは適宜いい感じに選択（chiveは動作確認済み）

話題データは、話題ごとに行を変え複数単語を含む

単語の重複はなしで、単語はモデルの辞書に含まれるものを使用

配置やファイル名の例は以下

.  
┣ test_word2Vec.ipynb  
┣ words.csv  
┗ dic  
　┗ chive-1.2-mc5_gensim  
　　┗ chive-1.2-mc5.kv  

# 無軌道雑談の可視化の例
## 何がしたいか

特定のVtuberの無軌道雑談配信の無軌道っぷりを確かめたい

無軌道雑談とは雑談の内容(軌道)を決めてないために、話題があっちこっちに行くことだと思う

話題間に関連性がない方が無軌道であると仮定する

話題間の関連性は話題に関する単語同時の相関を調べる

![b](https://user-images.githubusercontent.com/128278435/226158873-6407ae26-8396-48c6-9c54-d1ae3ba173be.png)

そのうち一番相関が強い物を話題間の関連性とする

![a](https://user-images.githubusercontent.com/128278435/226158886-3d49f50f-dfc2-490a-965b-1624f9c3d464.png)

これを可視化することで、無軌道雑談の無軌道っぷりを確かめたい

## 配信から話題の抽出

無軌道雑談配信を話題と単語に分ける

タイムスタンプのコメントを参考にしながら、csvデータを作成  

![csv](https://user-images.githubusercontent.com/128278435/226159139-00d40650-a4f1-4509-a9f6-1c0c356ff084.png)

話題ごとに行を分けて、関連する単語をいくつか記述する。

下は例で19話題53単語。

後述する辞書に含まれていない単語を含めず、単語の重複も許さない。

## 言語モデル
Word2Vecという手法を用いた

>word2vecは、単語を分散表現として表現することで、単語同士の意味的な関係を捉えることができます。例えば、「王」と「女王」、「国」や「国王」といった単語の関係性を、数学的に表現することができます。

とのこと

そのなかでもchiveを使用

>"chiVe" (チャイブ, Sudachi Vector) は、大規模コーパスと複数粒度分割に基づく日本語単語ベクトルです。Skip-gramアルゴリズムを元に、word2vec （gensim） を使用して単語分散表現を構築しています。学習には約1億のウェブページ文章を含む国立国語研究所の日本語ウェブコーパス（NWJC）を採用し、分かち書きにはワークスアプリケーションズの形態素解析器Sudachiを使用しています。
<https://github.com/WorksApplications/chiVe> より引用

使用したバージョンでは語彙数が319756あって、モデルデータは3.8GB

![c](https://user-images.githubusercontent.com/128278435/226158889-5ceb49e8-30d0-497e-a81c-ee8c1606977c.png)

図のようにコサイン類似度を用いることで、単語同士の類似度を計算する

## 実装

pythonでgensim, networkx, matplotlibで話題間ネットワークの可視化をした

jupyterで動かしてたので、配布の取り回しはちょっと悪い

![all_edge](https://user-images.githubusercontent.com/128278435/226158919-9b888592-af96-4895-99e0-4aa36b786d38.png)
これが冒頭の1枚目の画像に対応するグラフ
![near_edge](https://user-images.githubusercontent.com/128278435/226158923-22583a86-559c-408e-807e-c1f1d19462ee.png)
こっちが2枚目

両方ともノードの位置は同じである

下の画像では話題内の単語同士と、話題間で最も関連のある単語同士にのみエッジがある

そのため、話題の遷移の具合が見やすいはず

エッジやノードの色はカラーマップcoolを適応していて、小さい値が水色で大きい値がピンクになる

![cool](https://user-images.githubusercontent.com/128278435/226161268-5651f11b-e5cd-494e-b77b-b3d8ff1a68aa.png)

相関値は0～1で、1に近い方が類似度があるこれがどのくらいの値なのかピンとこないので例として次のような例もつけておく

* 「ニコニコ動画」と「ユーチューブ」の相関係数は 0.664
* 「ニコニコ動画」と「ツイッター」の相関係数は 0.489
* 「ニコニコ動画」と「ラーメン」の相関係数は 0.127
* 「ニコニコ動画」と「東京」の相関係数は 0.144
* 「ユーチューブ」と「ツイッター」の相関係数は 0.445
* 「ユーチューブ」と「ラーメン」の相関係数は 0.088
* 「ユーチューブ」と「東京」の相関係数は 0.184
* 「ツイッター」と「東京」の相関係数は 0.192
* 「ツイッター」と「ラーメン」の相関係数は 0.142
* 「ラーメン」と「東京」の相関係数は 0.215

これを見ると相関係数と直感がそこまで離れていないことがうかがえる

## 無軌道っぷりの評価
ここまでで求めた話題間の相関の数値をヒストグラムに起こす  
![hist](https://user-images.githubusercontent.com/128278435/226160779-cb806888-7272-47a1-a278-b10584dd9a4b.png)

0から1を20分割している  
0.2から0.25にピークがあり、範囲は0.1~0.45である  
つまり、この配信では
* 「ニコニコ動画」と「ツイッター」ほど相関のある話題の遷移は1つもない
* 少なくとも「ニコニコ動画」と「ラーメン」程度の相関がある話題の遷移をしている
* 多くの話題遷移は「ラーメン」と「東京」くらいの相関がある

さて、これがどれほどのものなのかを「走れメロス」と比較してみる
![hist_mel](https://user-images.githubusercontent.com/128278435/226165489-304bd824-49dd-4d48-9b64-d3ad5b94f957.png)


比較してみると、メロスの方が数字が大きい方に山がシフトしている  
これはメロスの方が話題の遷移に相関があるととらえることができる  

csvはこんな感じで作った  

  
![capme](https://user-images.githubusercontent.com/128278435/226165754-2422d724-1d2f-4086-8a92-3e6adc60d72c.png)  

別のVtuberの無軌道雑談配信でもやってみる  
![near_edge_mito](https://user-images.githubusercontent.com/128278435/226168571-7335883f-c492-4f5c-8107-3f840d6897b5.png)  

![hist_mito](https://user-images.githubusercontent.com/128278435/226168274-8c7b5bd6-72ce-460a-a269-db42dd1ae454.png)  
こっちは話題がぶっ飛ぶ時もあるけど、話題の遷移は自然なことが多いと考えられる  

## まとめ
csvの作成を手動で行っているため、ある程度作為的になってるかもしれない  
この辺を音声認識とかなんやかんやすると、もっと公平になるのかも  

